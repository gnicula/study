{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Analysis\n",
    "## Frequent Itemset Mining using Apriori Algorithm\n",
    "\n",
    "### Importing Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/retail_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the dataset represents items that were purchased together on the same day at same store.\n",
    "\n",
    "The dataset is a **sparse dataset** as relatively high percentage of data is NA or NAN or equivalent. \n",
    "\n",
    "Let's see all the unique items in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = (df['0'].unique())\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "To make use of the apriori module given by mlxtend library, we need to convert the dataset according to it's liking.\n",
    "apriori module requires a dataframe that has either 0 and 1 or True and False as data. \n",
    "The data we have is all string (name of items), we need to **One Hot Encode** the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_vals = []\n",
    "for index, row in df.iterrows():\n",
    "    labels = {}\n",
    "    uncommons = list(set(items) - set(row))\n",
    "    commons = list(set(items).intersection(row))\n",
    "    for uc in uncommons:\n",
    "        labels[uc] = 0\n",
    "    for com in commons:\n",
    "        labels[com] = 1\n",
    "    encoded_vals.append(labels)\n",
    "encoded_vals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the One Hot Encoded dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_df = pd.DataFrame(encoded_vals)\n",
    "ohe_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first observation from original dataset:\n",
    "['Bread', 'Wine','Eggs', 'Meat', 'Cheese', 'Pencil', 'Diaper']\n",
    "\n",
    "Take a look at first observation in our one hot encoded dataframe. Do you think OHE worked?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "apriori module from mlxtend library provides fast and efficient apriori implementation.  <br>\n",
    "<br>\n",
    "> **apriori(df, min_support=0.5, use_colnames=False, max_len=None, verbose=0, low_memory=False)**\n",
    "\n",
    "##### Parameters\n",
    "- ` df ` : One-Hot-Encoded DataFrame or DataFrame that has 0 and 1 or True and False as values\n",
    "- ` min_support ` : Floating point value between 0 and 1 that indicates the mininmum support required for an itemset to be selected. <br>\n",
    "<center> $ # of observation with item / total observation $ </center>\n",
    "- ` use_colnames ` : This allows to preserve column names for itemset making it more readable.\n",
    "- ` max_len ` : Max length of itemset generated. If not set, all possible lengths are evaluated.\n",
    "- ` verbose ` : Shows the number of iterations if >= 1 and low_memory is True. If =1 and low_memory is False , shows the number of combinations.\n",
    "- ` low_memory ` : <div style=\"text-align:justify\">If True, uses an iterator to search for combinations above min_support. Note that while low_memory=True should only be used for large dataset if memory resources are limited, because this implementation is approx. 3-6x slower than the default.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq_items = apriori(ohe_df, min_support=0.2, use_colnames=True, verbose=1)\n",
    "freq_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.6)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Support vs Confidence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(rules['support'], rules['confidence'], alpha=0.5)\n",
    "plt.xlabel('support')\n",
    "plt.ylabel('confidence')\n",
    "plt.title('Support vs Confidence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
