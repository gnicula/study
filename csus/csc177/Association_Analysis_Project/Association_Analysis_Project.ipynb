{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Analysis\n",
    "## Frequent Itemset Mining using Apriori Algorithm\n",
    "\n",
    "### Importing Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data\n",
    "For my dataset I choose a grocery dataset I found on Kaggle here:\n",
    "https://www.kaggle.com/datasets/heeraldedhia/groceries-dataset/ </br>\n",
    "The dataset has 38765 rows of the purchase orders of people from the grocery stores - and it needs a bit of pre-processing to extract a dataset of transactions as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Groceries_dataset.csv', sep=',')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting all transactions for association analysis\n",
    "I group by 'member_number' and 'date' in the original dataset and keep only the item list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(df.groupby(['Member_number','Date']))[0])\n",
    "transactions = [a[1]['itemDescription'].tolist() for a in list(df.groupby(['Member_number','Date']))]\n",
    "transactions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the transactions list (of lists) into a dataframe to be able to use methods from Tutorial_9_AssociationAnalysis\n",
    "The transactions dataset has 14963 rows (more than 10000 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.DataFrame(transactions)\n",
    "print(\"Columns: \", transactions_df.columns)\n",
    "transactions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each row of the dataframe represents items that were purchased together on the same day by the same member.\n",
    "The dataset is a **sparse dataset** as relatively high percentage of data is NA or NAN or equivalent. \n",
    "Let's see all the unique items in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = np.unique(transactions_df.values[transactions_df.values != None])\n",
    "print(\"Number of unique items: \", len(items))\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing - use the function provided in the tutorial\n",
    "\n",
    "apriori module requires a dataframe that has either 0 and 1 or True and False as data. \n",
    "The data we have is all string (name of items), we need to **One Hot Encode** the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom One Hot Encoding\n",
    "Note: I replaced 0 with False and 1 with True to get rid of the warning: </br>\n",
    "\"DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_vals = []\n",
    "for index, row in transactions_df.iterrows():\n",
    "    labels = {}\n",
    "    uncommons = list(set(items) - set(row))\n",
    "    commons = list(set(items).intersection(row))\n",
    "    for uc in uncommons:\n",
    "        labels[uc] = False\n",
    "    for com in commons:\n",
    "        labels[com] = True\n",
    "    encoded_vals.append(labels)\n",
    "encoded_vals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_df = pd.DataFrame(encoded_vals)\n",
    "print(\"All columns (items): \", ohe_df.columns)\n",
    "print(\"Number of single item transactions: \", len(ohe_df[ohe_df.apply(lambda x: sum(x) == 1, axis=1)]))\n",
    "# Drop rows with single item transaction. There are 205 of them and this speeds up the analysis a bit.\n",
    "ohe_df = ohe_df[ohe_df.apply(lambda x: sum(x) > 1, axis=1)]\n",
    "ohe_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to apply Apriori algorithm since we have a dataframe with one hot encoded rows for each transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apriori module from mlxtend library provides fast and efficient apriori implementation.  <br>\n",
    "<br>\n",
    "> **apriori(df, min_support=0.5, use_colnames=False, max_len=None, verbose=0, low_memory=False)**\n",
    "\n",
    "##### Parameters\n",
    "- ` df ` : One-Hot-Encoded DataFrame or DataFrame that has 0 and 1 or True and False as values\n",
    "- ` min_support ` : Floating point value between 0 and 1 that indicates the mininmum support required for an itemset to be selected. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq_items = apriori(ohe_df, min_support=0.01, use_colnames=True, verbose=1)\n",
    "# Print the 10 most frequently bought items\n",
    "freq_items.sort_values('support', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get results on different pairs of minimum support and minimum confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_thresholds = [0.001, 0.005, 0.01]\n",
    "confidence_thresholds = [0.01, 0.05, 0.1]\n",
    "# Keep all the resulted rules for all combinations of thresholds in a list of rules\n",
    "rules = []\n",
    "\n",
    "for support_threshold in support_thresholds:\n",
    "    for confidence_threshold in confidence_thresholds:\n",
    "        freq_items_t = apriori(ohe_df, min_support=support_threshold, use_colnames=True, verbose=1)\n",
    "        rules.append(association_rules(freq_items_t, metric=\"confidence\", min_threshold=confidence_threshold))\n",
    "\n",
    "# Print association rules for support = 0.01 and confidence = 0.1 (last computed)\n",
    "rules[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Support vs Confidence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rule_colors = matplotlib.cm.tab10(range(9))\n",
    "plt.rcParams['figure.figsize'] = [14, 10]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i, r in enumerate(rules):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    ax_c = ax[row, col]\n",
    "    ax_c.scatter(r['support'], r['confidence'], s=12, c=[rule_colors[i] if i<8 else 'blue'], alpha=0.75,\n",
    "                label=f\"(s, c) = ({support_thresholds[row]}, {confidence_thresholds[col]})\")\n",
    "    ax_c.legend()\n",
    "plt.suptitle('Confidence vs Support for different thresholds of support and confidence')\n",
    "fig.supylabel('Confidence')\n",
    "fig.supxlabel('Support')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of results and how they change with each pair of minimum support and minimum confidence\n",
    "\n",
    "1. At low thresholds of Support and Confidence there are many association rules selected by the alghoritm.<br>\n",
    "2. When Support threshold is increased only most frequent items are considered and the number of rules decreases.<br>\n",
    "3. When Confidence threshold is increased, only rules rules that have the ratio of support(item1â†’item2) / support(item1) higher than the threshold are kept so the number of rules decreases. <br>\n",
    "4. When both thresholds for Support and Confidence are increased only the rules that with higher Confidence and higher support are kept.<br>\n",
    "<br>\n",
    "For example, when Support >= 0.01 and Confidence >= 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support_threshold = 0.01, confidence_threshold = 0.05\n",
    "selected_rules = rules[7]\n",
    "selected_rules.sort_values('confidence', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for support_threshold = 0.01, the 3 most confident rules are:<br>\n",
    "<br>\n",
    "(yogurt) -> (whole milk)<br>\n",
    "(rolls/buns) -> (whole milk)<br>\n",
    "(other vegetables) -> (whole milk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Manager insights and actions\n",
    "\n",
    "### Decide which result sets are meaningful\n",
    "Manager can look at the item (product) support and decide to use a specific threshold.<br>\n",
    "For example, she/he can decide to work with top k=10 items in terms of antecedent support.<br>\n",
    "Then she/he can run apriori algorithm with that threshold of support and select a number of association rules or similarly a threshold for confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select items with highest support\n",
    "selected_rulse = rules[0]\n",
    "selected_rules.sort_values('support', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manager then decides the set of meaningful rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From above table, select support_threshold=0.01\n",
    "freq_items_t = apriori(ohe_df, min_support=0.01, use_colnames=True, verbose=1)\n",
    "manager_rules = association_rules(freq_items_t, metric=\"confidence\", min_threshold=0.01)\n",
    "manager_rules.sort_values('confidence', ascending=False)[['antecedents', 'consequents', 'confidence']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manager actions to improve sales, order inventory and ensure items are accessible easily\n",
    "<br>\n",
    "Based on the selected rules the manager can decide to:<br>\n",
    "\n",
    "1. Improve sales by discounting either the antecedents items or the consequents items or both.<br>\n",
    "For example, given the above selected association rules, the manager can decide to discount 'yogurt' while also preparing to increase 'whole milk' inventory in anticipation of higher sales of 'yogurt'. Another decision can be made to discount items if they are bought together, for example if the store has high inventory of already discounted 'soda' which cannot be further discounted, the manager can offer a discount only when 'soda' and 'whole milk' are bought together without discounting 'whole milk' itself.<br>\n",
    "2. Order inventory pro-actively, for example ordering 'other vegetables' together with {'rolls/buns' and 'whole milk'}. Also keeping inventory levels that can satisfy the most confident association rules.\n",
    "3. Arrange items to shelves/refrigerators in such a way that the most confident association rules are followed with items kept in close vicinity. For example keeping 'yogurt' and 'whole milk' nearby and similarly 'rolls/buns' and 'other vegetables'. Also the manager can identify the most frequently bought items and give them a shelf location that is easily accessible\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
